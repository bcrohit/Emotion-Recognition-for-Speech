{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ee1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import IPython.display as ipd\n",
    "import statistics as stats\n",
    "from collections import Counter\n",
    "from math import log\n",
    "import scipy.stats as scistat\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecb739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = 1024\n",
    "hop_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ade5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer(csv_file, mode, feature_vectors):\n",
    "    with open(csv_file, mode, newline='') as fp:\n",
    "        csv_writer = csv.writer(fp)\n",
    "        csv_writer.writerow(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2911075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_tendency_measures(vector, length, sr):\n",
    "        \n",
    "    # Mean\n",
    "    mean = np.mean(vector)\n",
    "    \n",
    "    # Median\n",
    "    median = stats.median(vector)\n",
    "    \n",
    "    # Maximum\n",
    "    maxi = max(vector)\n",
    "    \n",
    "    # Minimum\n",
    "    mini = min(vector)\n",
    "    \n",
    "    # Standard Deviation \n",
    "    std = np.std(vector)\n",
    "    \n",
    "    # SMA\n",
    "    sma = 0\n",
    "    time = (1/sr) * length\n",
    "    for sample in vector:\n",
    "        sma += abs(sample) * time\n",
    "        \n",
    "    # MAD\n",
    "    mad = scistat.median_abs_deviation(vector)\n",
    "    \n",
    "    # Entropy\n",
    "    ent = 0\n",
    "    counts = Counter(vector)\n",
    "    total = len(vector)\n",
    "    for count in counts.values():\n",
    "        prob = count / total\n",
    "        ent -= prob * log(prob, 2)\n",
    "        \n",
    "    # IQR\n",
    "    q1 = np.quantile(vector, 0.25)\n",
    "    q3 = np.quantile(vector, 0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Energy\n",
    "    energy = 0\n",
    "    for value in vector:\n",
    "        energy += value**2\n",
    "        \n",
    "    # Skewness\n",
    "    skew = scistat.skew(vector)\n",
    "    \n",
    "    # Kurtosis\n",
    "    kurt = scistat.kurtosis(vector)\n",
    "    \n",
    "    return np.array([mean, median, std, maxi, mini, sma, mad, ent, iqr, energy, skew, kurt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3c81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = # path to dataset -> r'D:\\SER-RO-MAHA\\Sample Speech Data'\n",
    "\n",
    "def extract_all_features(dataset_path, frame_size, hop_length, spectral_centroid=True, spectral_bandwidth=True):\n",
    "                   \n",
    "    for i, (dirpath, dirnames, files) in enumerate(os.walk(dataset_path)):\n",
    "        \n",
    "        if dirpath is not dataset_path:\n",
    "            print(f'Processing {dirpath}')\n",
    "            emotion = dirpath.split('\\\\')[-1]  \n",
    "            \n",
    "            for file in files:\n",
    "                print(file)\n",
    "                file_path = os.path.join(dirpath, file)\n",
    "                signal, sr = librosa.load(file_path)\n",
    "                \n",
    "                if spectral_centroid:\n",
    "                    sc_signal = librosa.feature.spectral_centroid(y=signal, sr=sr, n_fft=frame_size, hop_length=hop_length)[0]\n",
    "                    sc_signal = np.trim_zeros(sc_signal)\n",
    "                    vals = central_tendency_measures(sc_signal, len(signal), sr)\n",
    "                    writer('spectral_centroid_mesaures.csv', 'a', vals)\n",
    "                \n",
    "                if spectral_bandwidth:\n",
    "                    sb_signal = librosa.feature.spectral_bandwidth(y=signal, sr=sr, n_fft=frame_size, hop_length=hop_length)[0]\n",
    "                    sb_signal = np.trim_zeros(sb_signal)\n",
    "                    vals = central_tendency_measures(sb_signal, len(signal), sr)                    \n",
    "                    writer('spectral_bandwidth_mesaures.csv', 'a', vals)\n",
    "                \n",
    "                writer('freq_dom_measures_y.txt', 'a', [i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3be9966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\SER-RO-MAHA\\Sample Speech Data\\Anger\n",
      "03-01-05-01-01-01-01.wav\n",
      "JE_a15.wav\n",
      "Processing D:\\SER-RO-MAHA\\Sample Speech Data\\Disgust\n",
      "03-01-07-01-01-01-01.wav\n",
      "Processing D:\\SER-RO-MAHA\\Sample Speech Data\\Fear\n",
      "03-01-06-01-01-01-01.wav\n",
      "Processing D:\\SER-RO-MAHA\\Sample Speech Data\\Happy\n",
      "03-01-03-01-01-01-01.wav\n",
      "Processing D:\\SER-RO-MAHA\\Sample Speech Data\\Neutral\n",
      "03-01-01-01-01-01-01.wav\n",
      "Processing D:\\SER-RO-MAHA\\Sample Speech Data\\Sad\n",
      "03-01-04-01-01-01-01.wav\n",
      "Processing D:\\SER-RO-MAHA\\Sample Speech Data\\Surprise\n",
      "03-01-08-01-01-01-01.wav\n"
     ]
    }
   ],
   "source": [
    "extract_all_features(dataset_path, frame_size, hop_length, spectral_centroid=True, spectral_bandwidth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64c12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
